from sklearn.cluster import KMeans
from sklearn.metrics import davies_bouldin_score
from sklearn.decomposition import PCA

# KMeans clustering
k_range = range(2, 11)
db_scores = []
cluster_results = {}

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(scaled_features)
    db_index = davies_bouldin_score(scaled_features, labels)
    db_scores.append(db_index)
    cluster_results[k] = labels

# Optimal clusters
optimal_k = k_range[db_scores.index(min(db_scores))]
print(f"Optimal number of clusters: {optimal_k}")

# Visualization
pca = PCA(n_components=2)
pca_features = pca.fit_transform(scaled_features)
optimal_labels = cluster_results[optimal_k]

plt.scatter(pca_features[:, 0], pca_features[:, 1], c=optimal_labels, cmap='viridis', s=50)
plt.title("Customer Clusters")
plt.xlabel("PCA Feature 1")
plt.ylabel("PCA Feature 2")
plt.show()

# Save results
customer_features['Cluster'] = optimal_labels
customer_features.to_csv("FirstName_LastName_Clustering.csv", index=False)
